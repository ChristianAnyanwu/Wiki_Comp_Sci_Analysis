{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import wikipediaapi\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting vars and stops (pages that have too many links that arent relevant or useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPS = (\"International Standard Serial Number\",\n",
    "         \"International Standard Book Number\",\n",
    "         \"National Diet Library\",\n",
    "         \"International Standard Name Identifier\",\n",
    "         \"International Standard Book Number (Identifier)\",\n",
    "         \"Pubmed Identifier\", \"Pubmed Central\",\n",
    "         \"Digital Object Identifier\", \"Arxiv\",\n",
    "         \"Proc Natl Acad Sci Usa\", \"Bibcode\",\n",
    "         \"Library Of Congress Control Number\", \"Jstor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki = wikipediaapi.Wikipedia('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting SEED (starting site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting page\n",
    "SEED = \"Computer Science\".title()\n",
    "#number of layers\n",
    "max_layers = 2\n",
    "\n",
    "#bfs lists\n",
    "todo_list = [(0,SEED)]\n",
    "todo_set = set(SEED)\n",
    "done_set = set()\n",
    "\n",
    "#instantiating graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "#starting loop\n",
    "layer , page = todo_list[0]\n",
    "\n",
    "while layer < max_layers:\n",
    "    del todo_list[0]\n",
    "    done_set.add(page)\n",
    "    #print(layer,page)\n",
    "\n",
    "    try:\n",
    "        wikiPage = wiki.page(page)\n",
    "    except:\n",
    "        layer,page = todo_list[0]\n",
    "        #print(\"Could not load\", page)\n",
    "        continue\n",
    "    \n",
    "    for link in wikiPage.links:\n",
    "        link = link.title()\n",
    "        if link not in STOPS and not link.startswith(\"List Of\") and not link.startswith(\"Glossary Of\") and not (\":\"in link):\n",
    "            if link not in todo_set and link not in done_set:\n",
    "                todo_list.append((layer + 1, link))\n",
    "                todo_set.add(link)\n",
    "            G.add_edge(page, link)\n",
    "    layer, page = todo_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65845 nodes, 158077 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"{} nodes, {} edges\".format(len(G), nx.number_of_edges(G)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_edges_from(G.selfloop_edges())\n",
    "duplicates = [(node, node + \"s\") for node in G if node + \"s\" in G]\n",
    "for dup in duplicates:\n",
    "    G = nx.contracted_nodes(G, *dup, self_loops=False)\n",
    "duplicates = [(x, y) for x, y \n",
    "              in [(node, node.replace(\"-\", \" \")) for node in G]\n",
    "              if x != y and y in G]\n",
    "for dup in duplicates:\n",
    "    G = nx.contracted_nodes(G, *dup, self_loops=False)\n",
    "nx.set_node_attributes(G, 0, \"contraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22099 nodes, 114613 edges\n"
     ]
    }
   ],
   "source": [
    "core = [node for node, deg in dict(G.degree()).items() if deg >= 2]\n",
    "G = nx.subgraph(G, core)\n",
    "print(\"{} nodes, {} edges\".format(len(G), nx.number_of_edges(G)))\n",
    "# 2995 nodes, 11817 edges\n",
    "nx.write_graphml(G, \"compsci.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print top degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_indegree = sorted(dict(G.in_degree()).items(),\n",
    "                      reverse=True, key=itemgetter(1))[:100]\n",
    "#print(\"\\n\".join(map(lambda t: \"{} {}\".format(*reversed(t)), top_indegree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print full graph\n",
    "nx.write_gexf(G, \"graphFile_ComputerScience.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23075 122164\n"
     ]
    }
   ],
   "source": [
    "#load the graph file\n",
    "G = nx.read_graphml(\"compsci.graphml\")\n",
    "print(len(G.nodes()), len(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "#cull nodes with degree less than a set value\n",
    "node_degree_cutoff = 100\n",
    "\n",
    "to_keep = [node for node, deg in dict(G.degree()).items() if deg >= node_degree_cutoff]\n",
    "small = G.subgraph(to_keep)\n",
    "\n",
    "print(len(small.nodes()))\n",
    "nx.write_gexf(small, \"graphFile_ComputerScience_culled2.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Clustering Coefficient': 0.1223583072423935,\n",
       " 'Degree': 611,\n",
       " 'Eigenvector Centrality': 0.9718249141879425,\n",
       " 'In-Degree': 198,\n",
       " 'Modularity Class': 6,\n",
       " 'Out-Degree': 413,\n",
       " 'b': 251,\n",
       " 'contraction': 0,\n",
       " 'g': 255,\n",
       " 'label': 'Computer Science',\n",
       " 'r': 209,\n",
       " 'size': 10.0,\n",
       " 'x': -701.28564,\n",
       " 'y': 299.30154}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = nx.read_graphml(\"graphFile_SubGraph.graphml\")\n",
    "mod.nodes.get(\"Computer Science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
